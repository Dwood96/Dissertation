{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7cbc399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from here: https://medium.com/swlh/tweet-sentiment-analysis-using-python-for-complete-beginners-4aeb4456040\n",
    "# code also influenced from here: https://www.kaggle.com/code/ragnisah/text-data-cleaning-tweets-analysis/notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "Tweet_Data = pd.read_csv('Tweet_Data.csv')\n",
    "\n",
    "stop_words=stopwords.words('english')\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bb6d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58bfa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_Data['Tweet'] = Tweet_Data['Tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468db3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                  @TahaMArvas yes yes it is\n",
       "1        It has been an absolute shitter of a year, in multiple ways, and there's no getting around that....\n",
       "2                                                   @Dryad90 hairdresser's away until 6th January, nightmare\n",
       "3        #2009vs2019 \\n\\nTen years on and here I am, still looking like a budget Macaulay Culkin https://...\n",
       "4        The most predictable thing in the world is anti-trans activists rushing to defend homophobic cra...\n",
       "                                                        ...                                                 \n",
       "50849                                 The pathological animus of the New York Times  https://t.co/NP5Nv41Nu9\n",
       "50850    @Oooh_Matron Eh? Have never even written about any trans woman. Think you’ve confused me with so...\n",
       "50851                                                        https://t.co/8YG0BHe0J6 https://t.co/aZS1GsICmq\n",
       "50852                                                                           @ShireCleeve Thanks so much!\n",
       "50853                                                                                   @wpaddock Thank you!\n",
       "Name: Tweet, Length: 50854, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = Tweet_Data['Tweet']\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de50585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='View', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'View', data = Tweet_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae90a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Liberal         29806\n",
       "Conservative    21048\n",
       "Name: View, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data['View'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c4bcfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_Data['View'] = Tweet_Data['View'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f711182",
   "metadata": {},
   "outputs": [],
   "source": [
    "Truth_Query = Tweet_Data[(Tweet_Data['View'] != \"Liberal\") & (Tweet_Data['View'] != 'Conservative')]#finding the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52955a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29806, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data_Liberal = Tweet_Data.loc[(Tweet_Data[\"View\"] == \"Liberal\")]\n",
    "Tweet_Data_Liberal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "407c8fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21048, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data_Conservative = Tweet_Data.loc[(Tweet_Data[\"View\"] == \"Conservative\")]\n",
    "Tweet_Data_Conservative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa864265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data = pd.concat([Tweet_Data_Conservative, Tweet_Data_Liberal])\n",
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "656a01bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_usernames_links(tweet):\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub('http[^\\s]+','',tweet)\n",
    "    return tweet\n",
    "Tweet_Data['Tweet'] = Tweet_Data['Tweet'].apply(remove_usernames_links)\n",
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e575345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/xwlyd2kd5hb4q6nbz5k6s9v80000gn/T/ipykernel_81624/2987164781.py:3: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50854, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code from here: https://s-hosseinkhani1999.medium.com/remove-all-kind-of-emojis-with-the-demoji-package-python-643a530491f4\n",
    "import demoji\n",
    "demoji.download_codes()\n",
    "def remove_em(text):\n",
    "    dem = demoji.findall(text)\n",
    "    for item in dem.keys():\n",
    "        text = text.replace(item, '')\n",
    "    return text\n",
    "Tweet_Data['Tweet'] = Tweet_Data['Tweet'].apply(remove_em)\n",
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36aed345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code taken from here:https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/\n",
    "\n",
    "#library that contains punctuation\n",
    "import string\n",
    "string.punctuation\n",
    "\n",
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "Tweet_Data['clean_tweet']= Tweet_Data['Tweet'].apply(lambda x:remove_punctuation(x))\n",
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef8be7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>View</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29806</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-21 15:00:53+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Cackling from the SNP is easy to deal with. It’s obvious they still don’t  respect referendum re...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Cackling from the SNP is easy to deal with It’s obvious they still don’t  respect referendum res...</td>\n",
       "      <td>cackling from the snp is easy to deal with it’s obvious they still don’t  respect referendum res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29807</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-20 12:16:32+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Pleased to back in the  Chamber to speak in support of the EU Withdrawal Bill this morning. This...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Pleased to back in the  Chamber to speak in support of the EU Withdrawal Bill this morning This ...</td>\n",
       "      <td>pleased to back in the  chamber to speak in support of the eu withdrawal bill this morning this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29808</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-16 18:03:06+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Back to  today and looking forward to a busy week when we start a bright new chapter for our cou...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Back to  today and looking forward to a busy week when we start a bright new chapter for our cou...</td>\n",
       "      <td>back to  today and looking forward to a busy week when we start a bright new chapter for our cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29809</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-13 05:41:53+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Thank you   for your unstinting support. Great teamwork in the rain, the cold and the dark! All ...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Thank you   for your unstinting support Great teamwork in the rain the cold and the dark All pat...</td>\n",
       "      <td>thank you   for your unstinting support great teamwork in the rain the cold and the dark all pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29810</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-13 05:02:06+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Thank you Fareham for re-electing me to serve as your MP. Humbled, grateful and honoured to work...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Thank you Fareham for reelecting me to serve as your MP Humbled grateful and honoured to work fo...</td>\n",
       "      <td>thank you fareham for reelecting me to serve as your mp humbled grateful and honoured to work fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                       Date             User  \\\n",
       "29806           0  2019-12-21 15:00:53+00:00  SuellaBraverman   \n",
       "29807           1  2019-12-20 12:16:32+00:00  SuellaBraverman   \n",
       "29808           2  2019-12-16 18:03:06+00:00  SuellaBraverman   \n",
       "29809           3  2019-12-13 05:41:53+00:00  SuellaBraverman   \n",
       "29810           4  2019-12-13 05:02:06+00:00  SuellaBraverman   \n",
       "\n",
       "                                                                                                     Tweet  \\\n",
       "29806  Cackling from the SNP is easy to deal with. It’s obvious they still don’t  respect referendum re...   \n",
       "29807  Pleased to back in the  Chamber to speak in support of the EU Withdrawal Bill this morning. This...   \n",
       "29808  Back to  today and looking forward to a busy week when we start a bright new chapter for our cou...   \n",
       "29809  Thank you   for your unstinting support. Great teamwork in the rain, the cold and the dark! All ...   \n",
       "29810  Thank you Fareham for re-electing me to serve as your MP. Humbled, grateful and honoured to work...   \n",
       "\n",
       "               View  \\\n",
       "29806  Conservative   \n",
       "29807  Conservative   \n",
       "29808  Conservative   \n",
       "29809  Conservative   \n",
       "29810  Conservative   \n",
       "\n",
       "                                                                                               clean_tweet  \\\n",
       "29806  Cackling from the SNP is easy to deal with It’s obvious they still don’t  respect referendum res...   \n",
       "29807  Pleased to back in the  Chamber to speak in support of the EU Withdrawal Bill this morning This ...   \n",
       "29808  Back to  today and looking forward to a busy week when we start a bright new chapter for our cou...   \n",
       "29809  Thank you   for your unstinting support Great teamwork in the rain the cold and the dark All pat...   \n",
       "29810  Thank you Fareham for reelecting me to serve as your MP Humbled grateful and honoured to work fo...   \n",
       "\n",
       "                                                                                               tweet_lower  \n",
       "29806  cackling from the snp is easy to deal with it’s obvious they still don’t  respect referendum res...  \n",
       "29807  pleased to back in the  chamber to speak in support of the eu withdrawal bill this morning this ...  \n",
       "29808  back to  today and looking forward to a busy week when we start a bright new chapter for our cou...  \n",
       "29809  thank you   for your unstinting support great teamwork in the rain the cold and the dark all pat...  \n",
       "29810  thank you fareham for reelecting me to serve as your mp humbled grateful and honoured to work fo...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data['tweet_lower']= Tweet_Data['clean_tweet'].apply(lambda x: x.lower())\n",
    "Tweet_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "122413ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining function for tokenization\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize \n",
    "def tokenization(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "#applying function to the column\n",
    "Tweet_Data['tweet_tokenised']= Tweet_Data['tweet_lower'].apply(lambda x: tokenization(x))\n",
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f10697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e63d73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing nlp library\n",
    "import nltk\n",
    "#Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "Tweet_Data['no_stopwords']= Tweet_Data['tweet_tokenised'].apply(lambda x:remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc4b5f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25d00a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "#defining the object for stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "    return stem_text\n",
    "Tweet_Data['tweet_stemmed']=Tweet_Data['no_stopwords'].apply(lambda x: stemming(x))\n",
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01462657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "Tweet_Data['tweet_lemmatized']=Tweet_Data['no_stopwords'].apply(lambda x:lemmatizer(x))\n",
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530cf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f496d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-30 23:55:05+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>2 people were fatally shot and at least 4 others injured in an attack at the University of North...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-30 23:36:00+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>The letter adds to the growing evidence of a rift between them and is another sign of the anger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-30 23:23:33+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>Breaking News: Robert Mueller wrote a letter to the attorney general objecting to his characteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-30 23:00:04+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>Evening Briefing: Here's what you need to know at the end of the day https://t.co/9jh1P3TnCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-30 22:45:04+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>In Opinion\\n\\nPamela Druckerman writes: \"My French is still riddled with gaps and mistakes. When...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11016</th>\n",
       "      <td>1569</td>\n",
       "      <td>2019-04-01 02:35:54+00:00</td>\n",
       "      <td>BBCNews</td>\n",
       "      <td>Rapper Nipsey Hussle shot dead in Los Angeles https://t.co/IG0sciu2ZU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11017</th>\n",
       "      <td>1570</td>\n",
       "      <td>2019-04-01 02:11:11+00:00</td>\n",
       "      <td>BBCNews</td>\n",
       "      <td>Turkey local elections: Early result puts opposition ahead in Ankara https://t.co/eSWVM5g7sx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11018</th>\n",
       "      <td>1571</td>\n",
       "      <td>2019-04-01 00:41:07+00:00</td>\n",
       "      <td>BBCNews</td>\n",
       "      <td>Uncovering Nazi massacre of Jews on Belarus building site https://t.co/NPlglWROeB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11019</th>\n",
       "      <td>1572</td>\n",
       "      <td>2019-04-01 00:32:08+00:00</td>\n",
       "      <td>BBCNews</td>\n",
       "      <td>'A lot of the team started to get ill' https://t.co/lnW1NM0RaG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11020</th>\n",
       "      <td>1573</td>\n",
       "      <td>2019-04-01 00:16:23+00:00</td>\n",
       "      <td>BBCNews</td>\n",
       "      <td>Minimum wage rates rise, but bills go up too https://t.co/YcIY9AP43B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11021 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                       Date     User  \\\n",
       "0               0  2019-04-30 23:55:05+00:00  nytimes   \n",
       "1               1  2019-04-30 23:36:00+00:00  nytimes   \n",
       "2               2  2019-04-30 23:23:33+00:00  nytimes   \n",
       "3               3  2019-04-30 23:00:04+00:00  nytimes   \n",
       "4               4  2019-04-30 22:45:04+00:00  nytimes   \n",
       "...           ...                        ...      ...   \n",
       "11016        1569  2019-04-01 02:35:54+00:00  BBCNews   \n",
       "11017        1570  2019-04-01 02:11:11+00:00  BBCNews   \n",
       "11018        1571  2019-04-01 00:41:07+00:00  BBCNews   \n",
       "11019        1572  2019-04-01 00:32:08+00:00  BBCNews   \n",
       "11020        1573  2019-04-01 00:16:23+00:00  BBCNews   \n",
       "\n",
       "                                                                                                     Tweet  \n",
       "0      2 people were fatally shot and at least 4 others injured in an attack at the University of North...  \n",
       "1      The letter adds to the growing evidence of a rift between them and is another sign of the anger ...  \n",
       "2      Breaking News: Robert Mueller wrote a letter to the attorney general objecting to his characteri...  \n",
       "3             Evening Briefing: Here's what you need to know at the end of the day https://t.co/9jh1P3TnCH  \n",
       "4      In Opinion\\n\\nPamela Druckerman writes: \"My French is still riddled with gaps and mistakes. When...  \n",
       "...                                                                                                    ...  \n",
       "11016                                Rapper Nipsey Hussle shot dead in Los Angeles https://t.co/IG0sciu2ZU  \n",
       "11017         Turkey local elections: Early result puts opposition ahead in Ankara https://t.co/eSWVM5g7sx  \n",
       "11018                    Uncovering Nazi massacre of Jews on Belarus building site https://t.co/NPlglWROeB  \n",
       "11019                                       'A lot of the team started to get ill' https://t.co/lnW1NM0RaG  \n",
       "11020                                 Minimum wage rates rise, but bills go up too https://t.co/YcIY9AP43B  \n",
       "\n",
       "[11021 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Headlines = pd.read_csv('Headlines.csv')\n",
    "Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1c43e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_tokenised</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-30 23:55:05+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>2 people were fatally shot and at least 4 others injured in an attack at the University of North...</td>\n",
       "      <td>2 people were fatally shot and at least 4 others injured in an attack at the University of North...</td>\n",
       "      <td>2 people were fatally shot and at least 4 others injured in an attack at the university of north...</td>\n",
       "      <td>[2, people, were, fatally, shot, and, at, least, 4, others, injured, in, an, attack, at, the, un...</td>\n",
       "      <td>[2, people, fatally, shot, least, 4, others, injured, attack, university, north, carolina, charl...</td>\n",
       "      <td>[2, people, fatally, shot, least, 4, others, injured, attack, university, north, carolina, charl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-30 23:36:00+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>The letter adds to the growing evidence of a rift between them and is another sign of the anger ...</td>\n",
       "      <td>The letter adds to the growing evidence of a rift between them and is another sign of the anger ...</td>\n",
       "      <td>the letter adds to the growing evidence of a rift between them and is another sign of the anger ...</td>\n",
       "      <td>[the, letter, adds, to, the, growing, evidence, of, a, rift, between, them, and, is, another, si...</td>\n",
       "      <td>[letter, adds, growing, evidence, rift, another, sign, anger, among, special, counsel, ’, invest...</td>\n",
       "      <td>[letter, add, growing, evidence, rift, another, sign, anger, among, special, counsel, ’, investi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-30 23:23:33+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>Breaking News: Robert Mueller wrote a letter to the attorney general objecting to his characteri...</td>\n",
       "      <td>Breaking News Robert Mueller wrote a letter to the attorney general objecting to his characteriz...</td>\n",
       "      <td>breaking news robert mueller wrote a letter to the attorney general objecting to his characteriz...</td>\n",
       "      <td>[breaking, news, robert, mueller, wrote, a, letter, to, the, attorney, general, objecting, to, h...</td>\n",
       "      <td>[breaking, news, robert, mueller, wrote, letter, attorney, general, objecting, characterization,...</td>\n",
       "      <td>[breaking, news, robert, mueller, wrote, letter, attorney, general, objecting, characterization,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-30 23:00:04+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>Evening Briefing: Here's what you need to know at the end of the day</td>\n",
       "      <td>Evening Briefing Heres what you need to know at the end of the day</td>\n",
       "      <td>evening briefing heres what you need to know at the end of the day</td>\n",
       "      <td>[evening, briefing, heres, what, you, need, to, know, at, the, end, of, the, day]</td>\n",
       "      <td>[evening, briefing, heres, need, know, end, day]</td>\n",
       "      <td>[evening, briefing, here, need, know, end, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-30 22:45:04+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>In Opinion\\n\\nPamela Druckerman writes: \"My French is still riddled with gaps and mistakes. When...</td>\n",
       "      <td>In Opinion\\n\\nPamela Druckerman writes My French is still riddled with gaps and mistakes When I ...</td>\n",
       "      <td>in opinion\\n\\npamela druckerman writes my french is still riddled with gaps and mistakes when i ...</td>\n",
       "      <td>[in, opinion, pamela, druckerman, writes, my, french, is, still, riddled, with, gaps, and, mista...</td>\n",
       "      <td>[opinion, pamela, druckerman, writes, french, still, riddled, gaps, mistakes, try, tell, story, ...</td>\n",
       "      <td>[opinion, pamela, druckerman, writes, french, still, riddled, gap, mistake, try, tell, story, fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Date     User  \\\n",
       "0           0  2019-04-30 23:55:05+00:00  nytimes   \n",
       "1           1  2019-04-30 23:36:00+00:00  nytimes   \n",
       "2           2  2019-04-30 23:23:33+00:00  nytimes   \n",
       "3           3  2019-04-30 23:00:04+00:00  nytimes   \n",
       "4           4  2019-04-30 22:45:04+00:00  nytimes   \n",
       "\n",
       "                                                                                                 Tweet  \\\n",
       "0  2 people were fatally shot and at least 4 others injured in an attack at the University of North...   \n",
       "1  The letter adds to the growing evidence of a rift between them and is another sign of the anger ...   \n",
       "2  Breaking News: Robert Mueller wrote a letter to the attorney general objecting to his characteri...   \n",
       "3                                Evening Briefing: Here's what you need to know at the end of the day    \n",
       "4  In Opinion\\n\\nPamela Druckerman writes: \"My French is still riddled with gaps and mistakes. When...   \n",
       "\n",
       "                                                                                           clean_tweet  \\\n",
       "0  2 people were fatally shot and at least 4 others injured in an attack at the University of North...   \n",
       "1  The letter adds to the growing evidence of a rift between them and is another sign of the anger ...   \n",
       "2  Breaking News Robert Mueller wrote a letter to the attorney general objecting to his characteriz...   \n",
       "3                                  Evening Briefing Heres what you need to know at the end of the day    \n",
       "4  In Opinion\\n\\nPamela Druckerman writes My French is still riddled with gaps and mistakes When I ...   \n",
       "\n",
       "                                                                                           tweet_lower  \\\n",
       "0  2 people were fatally shot and at least 4 others injured in an attack at the university of north...   \n",
       "1  the letter adds to the growing evidence of a rift between them and is another sign of the anger ...   \n",
       "2  breaking news robert mueller wrote a letter to the attorney general objecting to his characteriz...   \n",
       "3                                  evening briefing heres what you need to know at the end of the day    \n",
       "4  in opinion\\n\\npamela druckerman writes my french is still riddled with gaps and mistakes when i ...   \n",
       "\n",
       "                                                                                       tweet_tokenised  \\\n",
       "0  [2, people, were, fatally, shot, and, at, least, 4, others, injured, in, an, attack, at, the, un...   \n",
       "1  [the, letter, adds, to, the, growing, evidence, of, a, rift, between, them, and, is, another, si...   \n",
       "2  [breaking, news, robert, mueller, wrote, a, letter, to, the, attorney, general, objecting, to, h...   \n",
       "3                    [evening, briefing, heres, what, you, need, to, know, at, the, end, of, the, day]   \n",
       "4  [in, opinion, pamela, druckerman, writes, my, french, is, still, riddled, with, gaps, and, mista...   \n",
       "\n",
       "                                                                                          no_stopwords  \\\n",
       "0  [2, people, fatally, shot, least, 4, others, injured, attack, university, north, carolina, charl...   \n",
       "1  [letter, adds, growing, evidence, rift, another, sign, anger, among, special, counsel, ’, invest...   \n",
       "2  [breaking, news, robert, mueller, wrote, letter, attorney, general, objecting, characterization,...   \n",
       "3                                                     [evening, briefing, heres, need, know, end, day]   \n",
       "4  [opinion, pamela, druckerman, writes, french, still, riddled, gaps, mistakes, try, tell, story, ...   \n",
       "\n",
       "                                                                                      tweet_lemmatized  \n",
       "0  [2, people, fatally, shot, least, 4, others, injured, attack, university, north, carolina, charl...  \n",
       "1  [letter, add, growing, evidence, rift, another, sign, anger, among, special, counsel, ’, investi...  \n",
       "2  [breaking, news, robert, mueller, wrote, letter, attorney, general, objecting, characterization,...  \n",
       "3                                                      [evening, briefing, here, need, know, end, day]  \n",
       "4  [opinion, pamela, druckerman, writes, french, still, riddled, gap, mistake, try, tell, story, fr...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Headlines['Tweet'] = Headlines['Tweet'].astype(str)\n",
    "Headlines['Tweet'] = Headlines['Tweet'].apply(remove_usernames_links)\n",
    "Headlines['Tweet'] = Headlines['Tweet'].apply(remove_em)\n",
    "Headlines['clean_tweet']= Headlines['Tweet'].apply(lambda x:remove_punctuation(x))\n",
    "Headlines['tweet_lower']= Headlines['clean_tweet'].apply(lambda x: x.lower())\n",
    "Headlines['tweet_tokenised']= Headlines['tweet_lower'].apply(lambda x: tokenization(x))\n",
    "Headlines['no_stopwords']= Headlines['tweet_tokenised'].apply(lambda x:remove_stopwords(x))\n",
    "Headlines['tweet_lemmatized']=Headlines['no_stopwords'].apply(lambda x:lemmatizer(x))\n",
    "Headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbb809a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/douglaswood/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# calculating the sentiment scores for tweets\n",
    "# code taken from here: https://www.analyticsvidhya.com/blog/2021/12/different-methods-for-calculating-sentiment-score-of-text/\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sent = SentimentIntensityAnalyzer()\n",
    "polarity = [round(sent.polarity_scores(i)['compound'], 2) for i in Tweet_Data['Tweet']]\n",
    "Tweet_Data['sentiment_score'] = polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bbb54ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_tokenised</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-30 23:55:05+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>2 people were fatally shot and at least 4 others injured in an attack at the University of North...</td>\n",
       "      <td>2 people were fatally shot and at least 4 others injured in an attack at the University of North...</td>\n",
       "      <td>2 people were fatally shot and at least 4 others injured in an attack at the university of north...</td>\n",
       "      <td>[2, people, were, fatally, shot, and, at, least, 4, others, injured, in, an, attack, at, the, un...</td>\n",
       "      <td>[2, people, fatally, shot, least, 4, others, injured, attack, university, north, carolina, charl...</td>\n",
       "      <td>[2, people, fatally, shot, least, 4, others, injured, attack, university, north, carolina, charl...</td>\n",
       "      <td>-0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-30 23:36:00+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>The letter adds to the growing evidence of a rift between them and is another sign of the anger ...</td>\n",
       "      <td>The letter adds to the growing evidence of a rift between them and is another sign of the anger ...</td>\n",
       "      <td>the letter adds to the growing evidence of a rift between them and is another sign of the anger ...</td>\n",
       "      <td>[the, letter, adds, to, the, growing, evidence, of, a, rift, between, them, and, is, another, si...</td>\n",
       "      <td>[letter, adds, growing, evidence, rift, another, sign, anger, among, special, counsel, ’, invest...</td>\n",
       "      <td>[letter, add, growing, evidence, rift, another, sign, anger, among, special, counsel, ’, investi...</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-30 23:23:33+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>Breaking News: Robert Mueller wrote a letter to the attorney general objecting to his characteri...</td>\n",
       "      <td>Breaking News Robert Mueller wrote a letter to the attorney general objecting to his characteriz...</td>\n",
       "      <td>breaking news robert mueller wrote a letter to the attorney general objecting to his characteriz...</td>\n",
       "      <td>[breaking, news, robert, mueller, wrote, a, letter, to, the, attorney, general, objecting, to, h...</td>\n",
       "      <td>[breaking, news, robert, mueller, wrote, letter, attorney, general, objecting, characterization,...</td>\n",
       "      <td>[breaking, news, robert, mueller, wrote, letter, attorney, general, objecting, characterization,...</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-30 23:00:04+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>Evening Briefing: Here's what you need to know at the end of the day</td>\n",
       "      <td>Evening Briefing Heres what you need to know at the end of the day</td>\n",
       "      <td>evening briefing heres what you need to know at the end of the day</td>\n",
       "      <td>[evening, briefing, heres, what, you, need, to, know, at, the, end, of, the, day]</td>\n",
       "      <td>[evening, briefing, heres, need, know, end, day]</td>\n",
       "      <td>[evening, briefing, here, need, know, end, day]</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-30 22:45:04+00:00</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>In Opinion\\n\\nPamela Druckerman writes: \"My French is still riddled with gaps and mistakes. When...</td>\n",
       "      <td>In Opinion\\n\\nPamela Druckerman writes My French is still riddled with gaps and mistakes When I ...</td>\n",
       "      <td>in opinion\\n\\npamela druckerman writes my french is still riddled with gaps and mistakes when i ...</td>\n",
       "      <td>[in, opinion, pamela, druckerman, writes, my, french, is, still, riddled, with, gaps, and, mista...</td>\n",
       "      <td>[opinion, pamela, druckerman, writes, french, still, riddled, gaps, mistakes, try, tell, story, ...</td>\n",
       "      <td>[opinion, pamela, druckerman, writes, french, still, riddled, gap, mistake, try, tell, story, fr...</td>\n",
       "      <td>-0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Date     User  \\\n",
       "0           0  2019-04-30 23:55:05+00:00  nytimes   \n",
       "1           1  2019-04-30 23:36:00+00:00  nytimes   \n",
       "2           2  2019-04-30 23:23:33+00:00  nytimes   \n",
       "3           3  2019-04-30 23:00:04+00:00  nytimes   \n",
       "4           4  2019-04-30 22:45:04+00:00  nytimes   \n",
       "\n",
       "                                                                                                 Tweet  \\\n",
       "0  2 people were fatally shot and at least 4 others injured in an attack at the University of North...   \n",
       "1  The letter adds to the growing evidence of a rift between them and is another sign of the anger ...   \n",
       "2  Breaking News: Robert Mueller wrote a letter to the attorney general objecting to his characteri...   \n",
       "3                                Evening Briefing: Here's what you need to know at the end of the day    \n",
       "4  In Opinion\\n\\nPamela Druckerman writes: \"My French is still riddled with gaps and mistakes. When...   \n",
       "\n",
       "                                                                                           clean_tweet  \\\n",
       "0  2 people were fatally shot and at least 4 others injured in an attack at the University of North...   \n",
       "1  The letter adds to the growing evidence of a rift between them and is another sign of the anger ...   \n",
       "2  Breaking News Robert Mueller wrote a letter to the attorney general objecting to his characteriz...   \n",
       "3                                  Evening Briefing Heres what you need to know at the end of the day    \n",
       "4  In Opinion\\n\\nPamela Druckerman writes My French is still riddled with gaps and mistakes When I ...   \n",
       "\n",
       "                                                                                           tweet_lower  \\\n",
       "0  2 people were fatally shot and at least 4 others injured in an attack at the university of north...   \n",
       "1  the letter adds to the growing evidence of a rift between them and is another sign of the anger ...   \n",
       "2  breaking news robert mueller wrote a letter to the attorney general objecting to his characteriz...   \n",
       "3                                  evening briefing heres what you need to know at the end of the day    \n",
       "4  in opinion\\n\\npamela druckerman writes my french is still riddled with gaps and mistakes when i ...   \n",
       "\n",
       "                                                                                       tweet_tokenised  \\\n",
       "0  [2, people, were, fatally, shot, and, at, least, 4, others, injured, in, an, attack, at, the, un...   \n",
       "1  [the, letter, adds, to, the, growing, evidence, of, a, rift, between, them, and, is, another, si...   \n",
       "2  [breaking, news, robert, mueller, wrote, a, letter, to, the, attorney, general, objecting, to, h...   \n",
       "3                    [evening, briefing, heres, what, you, need, to, know, at, the, end, of, the, day]   \n",
       "4  [in, opinion, pamela, druckerman, writes, my, french, is, still, riddled, with, gaps, and, mista...   \n",
       "\n",
       "                                                                                          no_stopwords  \\\n",
       "0  [2, people, fatally, shot, least, 4, others, injured, attack, university, north, carolina, charl...   \n",
       "1  [letter, adds, growing, evidence, rift, another, sign, anger, among, special, counsel, ’, invest...   \n",
       "2  [breaking, news, robert, mueller, wrote, letter, attorney, general, objecting, characterization,...   \n",
       "3                                                     [evening, briefing, heres, need, know, end, day]   \n",
       "4  [opinion, pamela, druckerman, writes, french, still, riddled, gaps, mistakes, try, tell, story, ...   \n",
       "\n",
       "                                                                                      tweet_lemmatized  \\\n",
       "0  [2, people, fatally, shot, least, 4, others, injured, attack, university, north, carolina, charl...   \n",
       "1  [letter, add, growing, evidence, rift, another, sign, anger, among, special, counsel, ’, investi...   \n",
       "2  [breaking, news, robert, mueller, wrote, letter, attorney, general, objecting, characterization,...   \n",
       "3                                                      [evening, briefing, here, need, know, end, day]   \n",
       "4  [opinion, pamela, druckerman, writes, french, still, riddled, gap, mistake, try, tell, story, fr...   \n",
       "\n",
       "   sentiment_score  \n",
       "0            -0.88  \n",
       "1            -0.08  \n",
       "2             0.38  \n",
       "3             0.00  \n",
       "4            -0.36  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment score for the newspaper headlines\n",
    "polarity = [round(sent.polarity_scores(i)['compound'], 2) for i in Headlines['Tweet']]\n",
    "Headlines['sentiment_score'] = polarity\n",
    "Headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cdca12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864646b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42bb60d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50854, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bfde68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "054aafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "google_word2vec = KeyedVectors.load_word2vec_format('/Users/douglaswood/Documents/Postgraduate/Dissertation/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "x = google_word2vec.word_vec(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ebac9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.42578125e-01 -3.68652344e-02  1.35742188e-01 -6.20117188e-02\n",
      "  7.95898438e-02  1.90429688e-02 -8.15429688e-02 -1.27929688e-01\n",
      " -2.95410156e-02  2.36328125e-01 -1.21582031e-01 -2.14843750e-01\n",
      "  1.29882812e-01 -2.70996094e-02 -5.20019531e-02  2.15820312e-01\n",
      " -1.81640625e-01  5.10253906e-02 -1.60156250e-01 -1.76757812e-01\n",
      "  1.83105469e-02 -4.12597656e-02 -2.32421875e-01 -1.03149414e-02\n",
      "  1.45507812e-01  5.24902344e-02 -3.96484375e-01 -1.92871094e-02\n",
      "  2.51770020e-03 -1.26953125e-02 -4.39453125e-02  3.07617188e-02\n",
      "  9.57031250e-02 -1.75781250e-01  1.04370117e-02  1.89453125e-01\n",
      " -2.36328125e-01  4.37011719e-02  2.81250000e-01 -2.07519531e-02\n",
      " -1.81640625e-01 -2.17773438e-01  2.33398438e-01  5.29785156e-02\n",
      " -1.13769531e-01  9.39941406e-03 -1.49414062e-01  1.99218750e-01\n",
      " -1.75781250e-01  3.16406250e-01  8.10546875e-02 -6.12792969e-02\n",
      " -1.52343750e-01 -1.81884766e-02  8.25195312e-02  8.74023438e-02\n",
      " -1.18652344e-01 -2.59765625e-01 -1.68457031e-02  1.87988281e-02\n",
      "  1.36108398e-02 -2.39257812e-01 -6.78710938e-02 -8.15429688e-02\n",
      "  2.18750000e-01  6.64062500e-02  1.27929688e-01  1.64062500e-01\n",
      "  2.28271484e-02 -1.38671875e-01 -9.42382812e-02  3.51562500e-02\n",
      "  7.37304688e-02 -1.06445312e-01  1.47705078e-02 -6.15234375e-02\n",
      "  2.48046875e-01  9.22851562e-02  1.45263672e-02  2.92968750e-01\n",
      "  2.47070312e-01 -3.46679688e-02 -1.92382812e-01  2.28881836e-03\n",
      "  1.33789062e-01  5.05371094e-02 -1.56250000e-01  2.02148438e-01\n",
      " -3.39355469e-02 -1.10351562e-01  1.31835938e-02 -1.84570312e-01\n",
      "  6.73828125e-02  9.22851562e-02  2.70996094e-02  1.44653320e-02\n",
      "  7.37304688e-02 -1.96289062e-01  6.39648438e-02  1.46484375e-01\n",
      "  3.67187500e-01 -3.67187500e-01  1.13281250e-01 -5.66406250e-02\n",
      "  5.27343750e-02 -1.66015625e-01  1.59179688e-01 -1.28906250e-01\n",
      "  2.21679688e-01  1.07910156e-01  1.56250000e-01  2.65625000e-01\n",
      " -1.50390625e-01  6.83593750e-02  2.08984375e-01 -1.70898438e-02\n",
      " -1.38671875e-01  3.26171875e-01  2.37304688e-01 -9.03320312e-02\n",
      "  9.27734375e-03 -8.59375000e-02 -1.22558594e-01  1.12792969e-01\n",
      "  1.17187500e-01 -3.32031250e-02  1.62109375e-01 -1.33789062e-01\n",
      "  1.45507812e-01 -8.64257812e-02 -9.13085938e-02 -5.37109375e-02\n",
      " -7.91015625e-02 -8.48388672e-03 -1.78710938e-01 -8.66699219e-03\n",
      "  4.12109375e-01  8.34960938e-02 -2.67578125e-01  4.02832031e-02\n",
      " -6.64062500e-02  8.74023438e-02 -1.87500000e-01 -9.37500000e-02\n",
      " -8.98437500e-02  6.49414062e-02  1.74804688e-01 -1.85546875e-01\n",
      " -1.49414062e-01 -2.10937500e-01  1.25976562e-01 -7.47070312e-02\n",
      " -1.94335938e-01 -1.91650391e-02 -1.89453125e-01 -1.84570312e-01\n",
      " -1.90429688e-01 -1.37695312e-01 -9.03320312e-02 -2.01416016e-02\n",
      "  3.88183594e-02  9.13085938e-02  2.55859375e-01 -1.35742188e-01\n",
      "  5.78613281e-02 -1.85546875e-01  4.58984375e-01  1.18164062e-01\n",
      "  4.40597534e-04 -4.90722656e-02  6.25000000e-02  1.10839844e-01\n",
      " -1.93359375e-01 -2.59765625e-01  1.83593750e-01  1.99218750e-01\n",
      " -1.17187500e-01 -1.66992188e-01 -1.43554688e-01  7.44628906e-03\n",
      " -1.25976562e-01  5.00488281e-02 -7.22656250e-02 -1.06201172e-02\n",
      "  2.11914062e-01  9.91210938e-02 -1.88476562e-01 -4.95605469e-02\n",
      "  8.83789062e-02 -1.50203705e-05 -1.26953125e-01  3.04687500e-01\n",
      "  2.49023438e-02  4.24194336e-03  6.64062500e-02 -3.26171875e-01\n",
      "  4.60937500e-01 -1.50390625e-01 -1.48437500e-01 -2.95410156e-02\n",
      "  3.10546875e-01  1.72851562e-01 -1.46484375e-01  6.93359375e-02\n",
      " -1.37695312e-01 -5.20019531e-02 -1.91406250e-01 -3.49121094e-02\n",
      "  1.97265625e-01 -2.34375000e-01  9.08203125e-02  3.24218750e-01\n",
      " -4.70703125e-01  1.70898438e-02 -2.35351562e-01 -8.05664062e-02\n",
      "  3.14453125e-01  2.20947266e-02 -1.42578125e-01 -2.79541016e-02\n",
      " -2.24609375e-01  2.69775391e-02  2.65625000e-01 -3.80859375e-02\n",
      "  2.61230469e-02  1.71875000e-01 -8.59375000e-02  7.76367188e-02\n",
      " -2.51464844e-02  8.78906250e-02  1.00708008e-02  1.62353516e-02\n",
      "  3.18359375e-01 -1.09375000e-01  2.85156250e-01  1.00097656e-01\n",
      " -3.06396484e-02  3.68652344e-02  1.30859375e-01  1.59179688e-01\n",
      " -1.11328125e-01  4.45556641e-03 -3.44238281e-02 -7.71484375e-02\n",
      " -2.11181641e-02 -2.12890625e-01 -1.24023438e-01 -1.15356445e-02\n",
      "  6.49414062e-02 -1.85546875e-02 -2.00195312e-01 -2.48046875e-01\n",
      "  9.22851562e-02 -1.48437500e-01 -6.93359375e-02  5.79833984e-03\n",
      " -3.41796875e-02  1.44531250e-01 -9.37500000e-02  1.26953125e-01\n",
      " -4.15039062e-02  3.16406250e-01 -7.03125000e-02  4.95605469e-02\n",
      "  1.95312500e-01  1.89208984e-02  1.09863281e-02 -7.47070312e-02\n",
      " -1.28906250e-01 -1.29882812e-01  1.03027344e-01  8.00781250e-02\n",
      "  6.25610352e-03  1.40991211e-02 -1.43554688e-01  1.36108398e-02\n",
      " -4.63867188e-02 -3.22265625e-01 -8.59375000e-02 -1.56250000e-01\n",
      "  1.46484375e-01  2.16796875e-01  1.81640625e-01 -1.22070312e-01\n",
      " -2.30468750e-01 -1.92871094e-02 -1.26953125e-02  1.09863281e-01\n",
      " -1.59179688e-01  1.17675781e-01  5.29785156e-02  2.08984375e-01\n",
      " -1.37695312e-01  1.62109375e-01 -1.72851562e-01  3.63769531e-02\n",
      " -1.25976562e-01 -1.44653320e-02 -1.26953125e-01 -2.59765625e-01]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9992cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abandoned due to hardware constraints\n",
    "#from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "#glove_input_file = '/Users/douglaswood/Documents/Postgraduate/Dissertation/glove.twitter.27B/glove.twitter.27B.50d.txt'\n",
    "#word2vec_output_file = '/Users/douglaswood/Documents/Postgraduate/Dissertation/glove.twitter.27B/glove.6B.50d.txt.word2vec'\n",
    "#glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4660d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function taken from here: https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Yotutube_WordVectors.ipynb\n",
    "def sent_vec_google(sent):\n",
    "    vector_size = google_word2vec.vector_size\n",
    "    google_word2vec_res = np.zeros(vector_size)\n",
    "    # print(wv_res)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in google_word2vec:\n",
    "            ctr += 1\n",
    "            google_word2vec_res += google_word2vec[w]\n",
    "    google_word2vec_res = google_word2vec_res/ctr\n",
    "    return google_word2vec_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d30802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe46ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29806    [0.072686767578125, 0.03382568359375, -0.00826416015625, 0.09387016296386719, -0.099069213867187...\n",
      "29807    [-0.030074270148026317, 0.05747935646458676, -0.018577174136513157, 0.05003171218068976, -0.0968...\n",
      "29808    [0.008065223693847656, 0.08214314778645833, 0.059438069661458336, 0.015360514322916666, 0.001251...\n",
      "29809    [0.031150124289772728, 0.05148835615678267, -0.0014537464488636363, 0.025479403409090908, 0.0045...\n",
      "29810    [-0.09069442749023438, 0.036504268646240234, 0.001956939697265625, 0.049072265625, 0.03057861328...\n",
      "                                                        ...                                                 \n",
      "29801    [0.0522796630859375, -0.0186279296875, 0.0580322265625, 0.137139892578125, -0.12333984375, -0.02...\n",
      "29802    [-0.013625081380208333, 0.0385009765625, 0.058854166666666666, 0.125048828125, -0.07775065104166...\n",
      "29803    [0.03856201171875, -0.015447998046875, 0.022607421875, 0.1852142333984375, -0.1039093017578125, ...\n",
      "29804    [0.06872081756591797, 0.045013427734375, 0.057343482971191406, 0.15865325927734375, -0.097003936...\n",
      "29805    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: google_vec, Length: 50854, dtype: object\n"
     ]
    }
   ],
   "source": [
    "Tweet_Data['google_vec'] = Tweet_Data['tweet_lemmatized'].apply(sent_vec_google)\n",
    "print(Tweet_Data['google_vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83be125f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>View</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_tokenised</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>google_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29806</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-21 15:00:53+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Cackling from the SNP is easy to deal with. It’s obvious they still don’t  respect referendum re...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Cackling from the SNP is easy to deal with It’s obvious they still don’t  respect referendum res...</td>\n",
       "      <td>cackling from the snp is easy to deal with it’s obvious they still don’t  respect referendum res...</td>\n",
       "      <td>[cackling, from, the, snp, is, easy, to, deal, with, it, ’, s, obvious, they, still, don, ’, t, ...</td>\n",
       "      <td>[cackling, snp, easy, deal, ’, obvious, still, ’, respect, referendum, results, stop, brexit, ge...</td>\n",
       "      <td>[cackl, snp, easi, deal, ’, obviou, still, ’, respect, referendum, result, stop, brexit, getbrex...</td>\n",
       "      <td>[cackling, snp, easy, deal, ’, obvious, still, ’, respect, referendum, result, stop, brexit, get...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>[0.072686767578125, 0.03382568359375, -0.00826416015625, 0.09387016296386719, -0.099069213867187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29807</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-20 12:16:32+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Pleased to back in the  Chamber to speak in support of the EU Withdrawal Bill this morning. This...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Pleased to back in the  Chamber to speak in support of the EU Withdrawal Bill this morning This ...</td>\n",
       "      <td>pleased to back in the  chamber to speak in support of the eu withdrawal bill this morning this ...</td>\n",
       "      <td>[pleased, to, back, in, the, chamber, to, speak, in, support, of, the, eu, withdrawal, bill, thi...</td>\n",
       "      <td>[pleased, back, chamber, speak, support, eu, withdrawal, bill, morning, bill, repairs, broken, t...</td>\n",
       "      <td>[pleas, back, chamber, speak, support, eu, withdraw, bill, morn, bill, repair, broken, trust, re...</td>\n",
       "      <td>[pleased, back, chamber, speak, support, eu, withdrawal, bill, morning, bill, repair, broken, tr...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>[-0.030074270148026317, 0.05747935646458676, -0.018577174136513157, 0.05003171218068976, -0.0968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29808</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-16 18:03:06+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Back to  today and looking forward to a busy week when we start a bright new chapter for our cou...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Back to  today and looking forward to a busy week when we start a bright new chapter for our cou...</td>\n",
       "      <td>back to  today and looking forward to a busy week when we start a bright new chapter for our cou...</td>\n",
       "      <td>[back, to, today, and, looking, forward, to, a, busy, week, when, we, start, a, bright, new, cha...</td>\n",
       "      <td>[back, today, looking, forward, busy, week, start, bright, new, chapter, country]</td>\n",
       "      <td>[back, today, look, forward, busi, week, start, bright, new, chapter, countri]</td>\n",
       "      <td>[back, today, looking, forward, busy, week, start, bright, new, chapter, country]</td>\n",
       "      <td>0.44</td>\n",
       "      <td>[0.008065223693847656, 0.08214314778645833, 0.059438069661458336, 0.015360514322916666, 0.001251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29809</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-13 05:41:53+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Thank you   for your unstinting support. Great teamwork in the rain, the cold and the dark! All ...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Thank you   for your unstinting support Great teamwork in the rain the cold and the dark All pat...</td>\n",
       "      <td>thank you   for your unstinting support great teamwork in the rain the cold and the dark all pat...</td>\n",
       "      <td>[thank, you, for, your, unstinting, support, great, teamwork, in, the, rain, the, cold, and, the...</td>\n",
       "      <td>[thank, unstinting, support, great, teamwork, rain, cold, dark, patriots, want, getbrexitdone, g...</td>\n",
       "      <td>[thank, unstint, support, great, teamwork, rain, cold, dark, patriot, want, getbrexitdon, ge2109]</td>\n",
       "      <td>[thank, unstinting, support, great, teamwork, rain, cold, dark, patriot, want, getbrexitdone, ge...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>[0.031150124289772728, 0.05148835615678267, -0.0014537464488636363, 0.025479403409090908, 0.0045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29810</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-13 05:02:06+00:00</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>Thank you Fareham for re-electing me to serve as your MP. Humbled, grateful and honoured to work...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Thank you Fareham for reelecting me to serve as your MP Humbled grateful and honoured to work fo...</td>\n",
       "      <td>thank you fareham for reelecting me to serve as your mp humbled grateful and honoured to work fo...</td>\n",
       "      <td>[thank, you, fareham, for, reelecting, me, to, serve, as, your, mp, humbled, grateful, and, hono...</td>\n",
       "      <td>[thank, fareham, reelecting, serve, mp, humbled, grateful, honoured, work, generalelection2019]</td>\n",
       "      <td>[thank, fareham, reelect, serv, mp, humbl, grate, honour, work, generalelection2019]</td>\n",
       "      <td>[thank, fareham, reelecting, serve, mp, humbled, grateful, honoured, work, generalelection2019]</td>\n",
       "      <td>0.83</td>\n",
       "      <td>[-0.09069442749023438, 0.036504268646240234, 0.001956939697265625, 0.049072265625, 0.03057861328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29801</th>\n",
       "      <td>4012</td>\n",
       "      <td>2019-01-02 21:00:43+00:00</td>\n",
       "      <td>KyleKulinski</td>\n",
       "      <td>All an elected Republican has to say is “I disagree with Trump that we should hold down the Cana...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>All an elected Republican has to say is “I disagree with Trump that we should hold down the Cana...</td>\n",
       "      <td>all an elected republican has to say is “i disagree with trump that we should hold down the cana...</td>\n",
       "      <td>[all, an, elected, republican, has, to, say, is, “, i, disagree, with, trump, that, we, should, ...</td>\n",
       "      <td>[elected, republican, say, “, disagree, trump, hold, canadian, pm, amp, fart, mouth, vote, let, ...</td>\n",
       "      <td>[elect, republican, say, “, disagre, trump, hold, canadian, pm, amp, fart, mouth, vote, let, ’, ...</td>\n",
       "      <td>[elected, republican, say, “, disagree, trump, hold, canadian, pm, amp, fart, mouth, vote, let, ...</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>[0.0522796630859375, -0.0186279296875, 0.0580322265625, 0.137139892578125, -0.12333984375, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>4013</td>\n",
       "      <td>2019-01-02 20:37:42+00:00</td>\n",
       "      <td>KyleKulinski</td>\n",
       "      <td>Ending drug war, freeing non violent offenders. Ending illegal nsa spying. Ending war in Afgha...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Ending drug war freeing non violent offenders Ending illegal nsa spying Ending war in Afghanistan</td>\n",
       "      <td>ending drug war freeing non violent offenders ending illegal nsa spying ending war in afghanistan</td>\n",
       "      <td>[ending, drug, war, freeing, non, violent, offenders, ending, illegal, nsa, spying, ending, war,...</td>\n",
       "      <td>[ending, drug, war, freeing, non, violent, offenders, ending, illegal, nsa, spying, ending, war,...</td>\n",
       "      <td>[end, drug, war, free, non, violent, offend, end, illeg, nsa, spi, end, war, afghanistan]</td>\n",
       "      <td>[ending, drug, war, freeing, non, violent, offender, ending, illegal, nsa, spying, ending, war, ...</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>[-0.013625081380208333, 0.0385009765625, 0.058854166666666666, 0.125048828125, -0.07775065104166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29803</th>\n",
       "      <td>4014</td>\n",
       "      <td>2019-01-02 20:33:40+00:00</td>\n",
       "      <td>KyleKulinski</td>\n",
       "      <td>Your definition of populist is \"more government intervention\" - that's absurd. Populism is just ...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Your definition of populist is more government intervention  thats absurd Populism is just suppo...</td>\n",
       "      <td>your definition of populist is more government intervention  thats absurd populism is just suppo...</td>\n",
       "      <td>[your, definition, of, populist, is, more, government, intervention, thats, absurd, populism, is...</td>\n",
       "      <td>[definition, populist, government, intervention, thats, absurd, populism, support, concerns, ord...</td>\n",
       "      <td>[definit, populist, govern, intervent, that, absurd, popul, support, concern, ordinari, peopl, s...</td>\n",
       "      <td>[definition, populist, government, intervention, thats, absurd, populism, support, concern, ordi...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>[0.03856201171875, -0.015447998046875, 0.022607421875, 0.1852142333984375, -0.1039093017578125, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29804</th>\n",
       "      <td>4015</td>\n",
       "      <td>2019-01-02 17:18:14+00:00</td>\n",
       "      <td>KyleKulinski</td>\n",
       "      <td>As far as I can tell only  and  have come out against PAYGO. Left MUST stand united because PAYG...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>As far as I can tell only  and  have come out against PAYGO Left MUST stand united because PAYGO...</td>\n",
       "      <td>as far as i can tell only  and  have come out against paygo left must stand united because paygo...</td>\n",
       "      <td>[as, far, as, i, can, tell, only, and, have, come, out, against, paygo, left, must, stand, unite...</td>\n",
       "      <td>[far, tell, come, paygo, left, must, stand, united, paygo, trojan, horse, killing, progressive, ...</td>\n",
       "      <td>[far, tell, come, paygo, left, must, stand, unit, paygo, trojan, hors, kill, progress, legisl, t...</td>\n",
       "      <td>[far, tell, come, paygo, left, must, stand, united, paygo, trojan, horse, killing, progressive, ...</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>[0.06872081756591797, 0.045013427734375, 0.057343482971191406, 0.15865325927734375, -0.097003936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29805</th>\n",
       "      <td>4016</td>\n",
       "      <td>2019-01-01 05:11:50+00:00</td>\n",
       "      <td>KyleKulinski</td>\n",
       "      <td></td>\n",
       "      <td>Liberal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50854 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                       Date             User  \\\n",
       "29806           0  2019-12-21 15:00:53+00:00  SuellaBraverman   \n",
       "29807           1  2019-12-20 12:16:32+00:00  SuellaBraverman   \n",
       "29808           2  2019-12-16 18:03:06+00:00  SuellaBraverman   \n",
       "29809           3  2019-12-13 05:41:53+00:00  SuellaBraverman   \n",
       "29810           4  2019-12-13 05:02:06+00:00  SuellaBraverman   \n",
       "...           ...                        ...              ...   \n",
       "29801        4012  2019-01-02 21:00:43+00:00     KyleKulinski   \n",
       "29802        4013  2019-01-02 20:37:42+00:00     KyleKulinski   \n",
       "29803        4014  2019-01-02 20:33:40+00:00     KyleKulinski   \n",
       "29804        4015  2019-01-02 17:18:14+00:00     KyleKulinski   \n",
       "29805        4016  2019-01-01 05:11:50+00:00     KyleKulinski   \n",
       "\n",
       "                                                                                                     Tweet  \\\n",
       "29806  Cackling from the SNP is easy to deal with. It’s obvious they still don’t  respect referendum re...   \n",
       "29807  Pleased to back in the  Chamber to speak in support of the EU Withdrawal Bill this morning. This...   \n",
       "29808  Back to  today and looking forward to a busy week when we start a bright new chapter for our cou...   \n",
       "29809  Thank you   for your unstinting support. Great teamwork in the rain, the cold and the dark! All ...   \n",
       "29810  Thank you Fareham for re-electing me to serve as your MP. Humbled, grateful and honoured to work...   \n",
       "...                                                                                                    ...   \n",
       "29801  All an elected Republican has to say is “I disagree with Trump that we should hold down the Cana...   \n",
       "29802    Ending drug war, freeing non violent offenders. Ending illegal nsa spying. Ending war in Afgha...   \n",
       "29803  Your definition of populist is \"more government intervention\" - that's absurd. Populism is just ...   \n",
       "29804  As far as I can tell only  and  have come out against PAYGO. Left MUST stand united because PAYG...   \n",
       "29805                                                                                                        \n",
       "\n",
       "               View  \\\n",
       "29806  Conservative   \n",
       "29807  Conservative   \n",
       "29808  Conservative   \n",
       "29809  Conservative   \n",
       "29810  Conservative   \n",
       "...             ...   \n",
       "29801       Liberal   \n",
       "29802       Liberal   \n",
       "29803       Liberal   \n",
       "29804       Liberal   \n",
       "29805       Liberal   \n",
       "\n",
       "                                                                                               clean_tweet  \\\n",
       "29806  Cackling from the SNP is easy to deal with It’s obvious they still don’t  respect referendum res...   \n",
       "29807  Pleased to back in the  Chamber to speak in support of the EU Withdrawal Bill this morning This ...   \n",
       "29808  Back to  today and looking forward to a busy week when we start a bright new chapter for our cou...   \n",
       "29809  Thank you   for your unstinting support Great teamwork in the rain the cold and the dark All pat...   \n",
       "29810  Thank you Fareham for reelecting me to serve as your MP Humbled grateful and honoured to work fo...   \n",
       "...                                                                                                    ...   \n",
       "29801  All an elected Republican has to say is “I disagree with Trump that we should hold down the Cana...   \n",
       "29802    Ending drug war freeing non violent offenders Ending illegal nsa spying Ending war in Afghanistan   \n",
       "29803  Your definition of populist is more government intervention  thats absurd Populism is just suppo...   \n",
       "29804  As far as I can tell only  and  have come out against PAYGO Left MUST stand united because PAYGO...   \n",
       "29805                                                                                                        \n",
       "\n",
       "                                                                                               tweet_lower  \\\n",
       "29806  cackling from the snp is easy to deal with it’s obvious they still don’t  respect referendum res...   \n",
       "29807  pleased to back in the  chamber to speak in support of the eu withdrawal bill this morning this ...   \n",
       "29808  back to  today and looking forward to a busy week when we start a bright new chapter for our cou...   \n",
       "29809  thank you   for your unstinting support great teamwork in the rain the cold and the dark all pat...   \n",
       "29810  thank you fareham for reelecting me to serve as your mp humbled grateful and honoured to work fo...   \n",
       "...                                                                                                    ...   \n",
       "29801  all an elected republican has to say is “i disagree with trump that we should hold down the cana...   \n",
       "29802    ending drug war freeing non violent offenders ending illegal nsa spying ending war in afghanistan   \n",
       "29803  your definition of populist is more government intervention  thats absurd populism is just suppo...   \n",
       "29804  as far as i can tell only  and  have come out against paygo left must stand united because paygo...   \n",
       "29805                                                                                                        \n",
       "\n",
       "                                                                                           tweet_tokenised  \\\n",
       "29806  [cackling, from, the, snp, is, easy, to, deal, with, it, ’, s, obvious, they, still, don, ’, t, ...   \n",
       "29807  [pleased, to, back, in, the, chamber, to, speak, in, support, of, the, eu, withdrawal, bill, thi...   \n",
       "29808  [back, to, today, and, looking, forward, to, a, busy, week, when, we, start, a, bright, new, cha...   \n",
       "29809  [thank, you, for, your, unstinting, support, great, teamwork, in, the, rain, the, cold, and, the...   \n",
       "29810  [thank, you, fareham, for, reelecting, me, to, serve, as, your, mp, humbled, grateful, and, hono...   \n",
       "...                                                                                                    ...   \n",
       "29801  [all, an, elected, republican, has, to, say, is, “, i, disagree, with, trump, that, we, should, ...   \n",
       "29802  [ending, drug, war, freeing, non, violent, offenders, ending, illegal, nsa, spying, ending, war,...   \n",
       "29803  [your, definition, of, populist, is, more, government, intervention, thats, absurd, populism, is...   \n",
       "29804  [as, far, as, i, can, tell, only, and, have, come, out, against, paygo, left, must, stand, unite...   \n",
       "29805                                                                                                   []   \n",
       "\n",
       "                                                                                              no_stopwords  \\\n",
       "29806  [cackling, snp, easy, deal, ’, obvious, still, ’, respect, referendum, results, stop, brexit, ge...   \n",
       "29807  [pleased, back, chamber, speak, support, eu, withdrawal, bill, morning, bill, repairs, broken, t...   \n",
       "29808                    [back, today, looking, forward, busy, week, start, bright, new, chapter, country]   \n",
       "29809  [thank, unstinting, support, great, teamwork, rain, cold, dark, patriots, want, getbrexitdone, g...   \n",
       "29810      [thank, fareham, reelecting, serve, mp, humbled, grateful, honoured, work, generalelection2019]   \n",
       "...                                                                                                    ...   \n",
       "29801  [elected, republican, say, “, disagree, trump, hold, canadian, pm, amp, fart, mouth, vote, let, ...   \n",
       "29802  [ending, drug, war, freeing, non, violent, offenders, ending, illegal, nsa, spying, ending, war,...   \n",
       "29803  [definition, populist, government, intervention, thats, absurd, populism, support, concerns, ord...   \n",
       "29804  [far, tell, come, paygo, left, must, stand, united, paygo, trojan, horse, killing, progressive, ...   \n",
       "29805                                                                                                   []   \n",
       "\n",
       "                                                                                             tweet_stemmed  \\\n",
       "29806  [cackl, snp, easi, deal, ’, obviou, still, ’, respect, referendum, result, stop, brexit, getbrex...   \n",
       "29807  [pleas, back, chamber, speak, support, eu, withdraw, bill, morn, bill, repair, broken, trust, re...   \n",
       "29808                       [back, today, look, forward, busi, week, start, bright, new, chapter, countri]   \n",
       "29809    [thank, unstint, support, great, teamwork, rain, cold, dark, patriot, want, getbrexitdon, ge2109]   \n",
       "29810                 [thank, fareham, reelect, serv, mp, humbl, grate, honour, work, generalelection2019]   \n",
       "...                                                                                                    ...   \n",
       "29801  [elect, republican, say, “, disagre, trump, hold, canadian, pm, amp, fart, mouth, vote, let, ’, ...   \n",
       "29802            [end, drug, war, free, non, violent, offend, end, illeg, nsa, spi, end, war, afghanistan]   \n",
       "29803  [definit, populist, govern, intervent, that, absurd, popul, support, concern, ordinari, peopl, s...   \n",
       "29804  [far, tell, come, paygo, left, must, stand, unit, paygo, trojan, hors, kill, progress, legisl, t...   \n",
       "29805                                                                                                   []   \n",
       "\n",
       "                                                                                          tweet_lemmatized  \\\n",
       "29806  [cackling, snp, easy, deal, ’, obvious, still, ’, respect, referendum, result, stop, brexit, get...   \n",
       "29807  [pleased, back, chamber, speak, support, eu, withdrawal, bill, morning, bill, repair, broken, tr...   \n",
       "29808                    [back, today, looking, forward, busy, week, start, bright, new, chapter, country]   \n",
       "29809  [thank, unstinting, support, great, teamwork, rain, cold, dark, patriot, want, getbrexitdone, ge...   \n",
       "29810      [thank, fareham, reelecting, serve, mp, humbled, grateful, honoured, work, generalelection2019]   \n",
       "...                                                                                                    ...   \n",
       "29801  [elected, republican, say, “, disagree, trump, hold, canadian, pm, amp, fart, mouth, vote, let, ...   \n",
       "29802  [ending, drug, war, freeing, non, violent, offender, ending, illegal, nsa, spying, ending, war, ...   \n",
       "29803  [definition, populist, government, intervention, thats, absurd, populism, support, concern, ordi...   \n",
       "29804  [far, tell, come, paygo, left, must, stand, united, paygo, trojan, horse, killing, progressive, ...   \n",
       "29805                                                                                                   []   \n",
       "\n",
       "       sentiment_score  \\\n",
       "29806             0.65   \n",
       "29807             0.80   \n",
       "29808             0.44   \n",
       "29809             0.87   \n",
       "29810             0.83   \n",
       "...                ...   \n",
       "29801            -0.20   \n",
       "29802            -0.94   \n",
       "29803             0.40   \n",
       "29804            -0.38   \n",
       "29805             0.00   \n",
       "\n",
       "                                                                                                google_vec  \n",
       "29806  [0.072686767578125, 0.03382568359375, -0.00826416015625, 0.09387016296386719, -0.099069213867187...  \n",
       "29807  [-0.030074270148026317, 0.05747935646458676, -0.018577174136513157, 0.05003171218068976, -0.0968...  \n",
       "29808  [0.008065223693847656, 0.08214314778645833, 0.059438069661458336, 0.015360514322916666, 0.001251...  \n",
       "29809  [0.031150124289772728, 0.05148835615678267, -0.0014537464488636363, 0.025479403409090908, 0.0045...  \n",
       "29810  [-0.09069442749023438, 0.036504268646240234, 0.001956939697265625, 0.049072265625, 0.03057861328...  \n",
       "...                                                                                                    ...  \n",
       "29801  [0.0522796630859375, -0.0186279296875, 0.0580322265625, 0.137139892578125, -0.12333984375, -0.02...  \n",
       "29802  [-0.013625081380208333, 0.0385009765625, 0.058854166666666666, 0.125048828125, -0.07775065104166...  \n",
       "29803  [0.03856201171875, -0.015447998046875, 0.022607421875, 0.1852142333984375, -0.1039093017578125, ...  \n",
       "29804  [0.06872081756591797, 0.045013427734375, 0.057343482971191406, 0.15865325927734375, -0.097003936...  \n",
       "29805  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[50854 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e597d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained word2vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "training_docs = Tweet_Data['tweet_lemmatized']\n",
    "model= Word2Vec(training_docs,size=300,workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbd4e9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7feb34448430>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638df46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00ee9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec_corpus(sent):\n",
    "    vector_size = model.wv.vector_size\n",
    "    model.wv_res = np.zeros(vector_size)\n",
    "    # print(wv_res)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in model.wv:\n",
    "            ctr += 1\n",
    "            model.wv_res += model.wv[w]\n",
    "    model.wv_res = model.wv_res/ctr\n",
    "    return model.wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f40316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29806    [0.5428762904235295, 0.07534178599183049, 0.2306769506207534, -0.2055336707936866, 0.26518226047...\n",
      "29807    [0.319691495762931, 0.07972298853565007, 0.17779862321913242, -0.1366099293033282, 0.14960629152...\n",
      "29808    [0.29358814905087155, 0.04012699184628824, 0.1649115172525247, 0.0004280608457823594, 0.18051193...\n",
      "29809    [0.2418537639081478, 0.12357848630053922, 0.23094185888767244, -0.11671876329928636, 0.092373477...\n",
      "29810    [0.25228902055985397, 0.0855513459795879, 0.168199947103858, -0.0624973148935371, 0.087706319481...\n",
      "                                                        ...                                                 \n",
      "29801    [0.3114511847658002, 0.039619572050667004, 0.2948766481131315, -0.3076605784058895, 0.0745591168...\n",
      "29802    [0.20577596819826535, -0.04040774503456695, 0.22204829419830016, -0.15503174319331134, 0.0417105...\n",
      "29803    [0.31637084409594535, 0.10740776457823813, 0.2954829927533865, -0.13824397465214133, 0.077736065...\n",
      "29804    [0.2810127369593829, 0.03757987738936208, 0.22439072700217366, -0.2019414242822677, 0.0811849125...\n",
      "29805    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: trained_vec, Length: 50854, dtype: object\n"
     ]
    }
   ],
   "source": [
    "Tweet_Data['trained_vec'] = Tweet_Data['tweet_lemmatized'].apply(sent_vec_corpus)\n",
    "print(Tweet_Data['trained_vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d80d9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorising the documents\n",
    "# code inspired from here: https://thinkinfi.com/gensim-doc2vec-python-implementation/#:~:text=Doc2vec%20(also%20known%20as%3A%20paragraph2vec,instead%20of%20word%20in%20Word2Vec)\n",
    "# code inspired form here: https://towardsdatascience.com/how-to-vectorize-text-in-dataframes-for-nlp-tasks-3-simple-techniques-82925a5600db\n",
    "#tweet_list = Tweet_Data['tweet_lemmatized'].tolist()\n",
    "#tweet_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db960c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "#tokenize and tag the card text\n",
    "#tweet_tagged = [TaggedDocument(d, [i]) for i, d in enumerate(tweet_list)]\n",
    "#tweet_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f38c51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate model\n",
    "#model = Doc2Vec(vector_size=64, window=2, min_count=1, workers=8, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "848e8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build vocab\n",
    "#model.build_vocab(tweet_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cbd55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "#model.train(tweet_tagged, total_examples=model.corpus_count\n",
    "#            , epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6343199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate vectors\n",
    "#doc2vec_vectors = [model.infer_vector((Tweet_Data['tweet_lemmatized'][i])) \n",
    "#            for i in range(0,len(Tweet_Data['tweet_lemmatized']))]\n",
    "#doc2vec_vectors\n",
    "\n",
    "#abandoned due to hardware constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40f9cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building tf-idf vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tweets = Tweet_Data['clean_tweet'].tolist()\n",
    "Vectorizer = TfidfVectorizer()\n",
    "vectors = Vectorizer.fit_transform(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_Data['tfidf_vectors'] = vectors.todense()\n",
    "Tweet_Data['tfidf_vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb81d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bb8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81d542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e016e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892445c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525106c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6ee71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c583a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9813da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ebf15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66dad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e08e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fa8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf6951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e216f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa768bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee67582b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7798dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1e285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a49e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0831b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c2c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c18896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51c029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5755fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232044d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fe7147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "# Start with one review:\n",
    "df_Liberal = Tweet_Data[Tweet_Data['View']=='Liberal']\n",
    "df_Conservative = Tweet_Data[Tweet_Data['View']==\"Conservative\"]\n",
    "tweet_All = \" \".join(review for review in Tweet_Data)\n",
    "tweet_df_Liberal = \" \".join(review for review in df_Liberal.Tweet)\n",
    "tweet_df_Conservative = \" \".join(review for review in df_Conservative.Tweet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize  = (30,30))\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_All)\n",
    "wordcloud_ADR = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_df_Liberal)\n",
    "wordcloud_NADR = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_df_Conservative)\n",
    "\n",
    "ax[0].imshow(wordcloud_ALL, interpolation='bilinear')\n",
    "ax[0].set_title('All Tweets', fontsize=30)\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(wordcloud_ADR, interpolation='bilinear')\n",
    "ax[1].set_title('Liberal Tweets',fontsize=30)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(wordcloud_NADR, interpolation='bilinear')\n",
    "ax[2].set_title('Conservative Tweets',fontsize=30)\n",
    "ax[2].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6615d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d9a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
